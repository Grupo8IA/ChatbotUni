{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Configuración 1 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq3ziQeUmC5K"
      },
      "source": [
        "# Entrenamiento del modelo (Configuración 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No68nVceltdz"
      },
      "source": [
        "* La cantidad máxima de palabras por cada sentencia es de 10.\n",
        "* Batch size: 518\n",
        "* Épocas: 60\n",
        "* Learnig rate: 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMpxC_Gqr6Nx",
        "outputId": "b7b9ed5b-5be5-49e4-df5a-3e3df36ef29c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/iA"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/.shortcut-targets-by-id/1ccQ0NRVtxcnMDQHOrldbGFQDfXPWk9Jj/iA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yAFs-CzWAp3",
        "outputId": "46d38a6b-4b38-47f2-cd67-cc46d8a88b8b"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20.txt\n",
            "BackwardForward.ipynb\n",
            "checkpoint-10ML-30ep-META-512bz-loss29-valoss41.pt\n",
            "checkpoint-10ML-30ep-META-512bz-loss30-valoss41-con-tildes.pt\n",
            "checkpoint-10ML-60ep-META-512bz-loss26-valoss46-con-tildes2.pt\n",
            "checkpoint-15ML-20EP.pt\n",
            "checkpoint-15ML-30ep-META-512bz-loss40-valoss54-con-tildes.pt\n",
            "checkpoint-20ML-15ep-data-METALW-512bz-con-tildes-300em-300h.pt\n",
            "checkpoint-20ML-25ep-data-METALW-512bz-con-tildes-300em-300h.pt\n",
            "checkpoint-20ML-35ep-data-METALW-512bz-con-tildes-300em-300h.pt\n",
            "checkpoint-20ML-50ep-data-METALW-512bz-con-tildes-300em-300h.pt\n",
            "checkpoint-20ML-75ep-data-METALW-512bz-con-tildes-300em-300h.pt\n",
            "checkpoint-20ML-85ep-data-METALW-512bz-con-tildes-300em-300h.pt\n",
            "checkpoint-25ML-13EP-300BS.pt\n",
            "checkpoint-25ML-15ep-data-METALW-512bz-con-tildes-200em-200h.pt\n",
            "checkpoint-25ML-25ep-data-METALW-512bz-con-tildes-200em-200h.pt\n",
            "checkpoint-25ML-35ep-data-METALW-512bz-con-tildes-200em-200h.pt\n",
            "checkpoint-25ML-50ep-data-METALW-512bz-con-tildes-200em-200h.pt\n",
            "checkpoint-25ML-65ep-data-METALW-512bz-con-tildes-200em-200h.pt\n",
            "checkpoint2.pt\n",
            "checkpoint-50ML-20EP.pt\n",
            "checkpoint.pt\n",
            "\u001b[0m\u001b[01;34mcontinnuacion\u001b[0m/\n",
            "cultura_general_1\n",
            "data_freider.txt\n",
            "\u001b[01;34mData_PC2\u001b[0m/\n",
            "final.txt\n",
            "GRL_Book.pdf\n",
            "METALW.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYoOzMr0kTpg"
      },
      "source": [
        "### Preparación de la data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoFvqUsfkFGm"
      },
      "source": [
        "import torch\n",
        "from torch.jit import script\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import re\n",
        "import unicodedata\n",
        "from io import open\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "MAX_LENGTH = 10 # Cantidad de palabras máxima por cada sentencia"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COocxGdvfALW"
      },
      "source": [
        "# Linea: pares de sentencias separadas por \\t\n",
        "# Sentencia: Texto de la pregunta o la respuesta.\n",
        "# par: Un vector, cada vector contiene dos senticias: pregunta y la respuesta\n",
        "\n",
        "PAD_token = 0  # Token para rellenar las sentencias con una cantidad menor a MAX_LENGTH\n",
        "SOS_token = 1  # Token que indica el inicio de la sentencia\n",
        "EOS_token = 2  # Token que indica el final de la sentencia\n",
        "\n",
        "# Objeto Voc: Procesará cada sentencia de casa línea \n",
        "# Nos ayudará a generar una mapeo de cada palabra a indices (números)\n",
        "# lo que permitirá obtener el índice que corresponde a cada palabra, la palabra que le\n",
        "# corresponde a cada índice y la cantidad de veces que una palabra se repíte\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {\"PAD\":PAD_token , \"SOS\":SOS_token , \"EOS\":EOS_token }\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Los 3 tokens inicializados SOS, EOS, PAD\n",
        "\n",
        "    def agregarSentencia(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.agregarPalabra(word)\n",
        "\n",
        "    def agregarPalabra(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    def indiceDeSentencia(self, sentencia):\n",
        "        return [self.word2index[word] for word in sentencia.split(' ')] + [EOS_token]\n",
        "\n",
        "    def sentenciaDeIndice(self, indice):\n",
        "        return [self.index2word[idx] for idx in indice]\n",
        "\n",
        "    # Remueve las palabras que se repiten menos de una cierta cantidad de veces\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "\n",
        "        # Reinicializamos los diccionarios\n",
        "        self.word2index = {\"PAD\":PAD_token , \"SOS\":SOS_token , \"EOS\":EOS_token }\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 # Los 3 tokens inicializados SOS, EOS, PAD\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.agregarPalabra(word)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltLAHNyz9K3F",
        "outputId": "e8438846-e22b-469e-b86a-2daf4e09ddd8"
      },
      "source": [
        "# Función que normalizará cada sentencia\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        # c for c in unicodedata.normalize('NFC', s) # Para eliminar\n",
        "        c for c in unicodedata.normalize('NFC', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Normalizamos cada sentencia\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip()) # Normalizamos y pasamos todas las letras a minúsculas\n",
        "    # Pasamos cada sentencia a minúsculas, removemos los espacios y carácteres que no son letras excluyendo los números\n",
        "    s = re.sub(r\"([.¡!¿?])\", r\" \\1\", s)  # Mantenemos los signos interrogación y exclamación\n",
        "    s = re.sub(r\"[^A-zÁ-ú.¡!¿?0-9]+\", r\" \", s) # Mantenemos las tildes y números\n",
        "    # s = re.sub(r\"\\¿\", r\"¿ \", s) # Agregamos un espacio a los signos de interrogación para que se cuente como una palabra\n",
        "    # s = re.sub(r\"\\?\", r\" ?\", s) # Agregamos un espacio a los signos de interrogación para que se cuente como una palabra\n",
        "    # s = re.sub(r\"\\¡\", r\"¡ \", s) # Agregamos un espacio a los signos de exclamación para que se cuente como una palabra\n",
        "    # s = re.sub(r\"\\!\", r\" !\", s) # Agregamos un espacio a los signos de exclamación para que se cuente como una palabra\n",
        "    # s = re.sub(r\"\\s+\", r\" \", s).strip() # Eliminamos los espacios demás\n",
        "    # s = re.sub(r\"\\.\", r\"\", s).strip() # Eliminamos los puntos\n",
        "\n",
        "    # s = re.sub(r\"([¡!¿?])\", r\" \\1\", s)\n",
        "    # s = re.sub(r\"[^A-z.¡!¿?0-9]+\", r\" \", s) # Elimina tildes\n",
        "    s = re.sub(r\"\\.\", r\"\", s)\n",
        "    s = re.sub(r\"\\¿\\s+\", r\"¿\", s)\n",
        "    s = re.sub(r\"\\s+\\?\", r\"?\", s)\n",
        "    s = re.sub(r\"\\¡\\s\", r\"¡\", s)\n",
        "    s = re.sub(r\"\\!\\s\", r\"!\", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "# Leemos las lineas del archivo y devolvemos los pares y un objeto Voc\n",
        "def readVocs(datafile, corpus_name):\n",
        "    print(\"Leyendo líneas...\")\n",
        "    # Leemos el archivo y devuelve una lista de líneas\n",
        "    lines = open(datafile, encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    # Dividimos cada linea en pares, normaliza normalizando cada sentencia\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    voc = Voc(corpus_name)\n",
        "    return voc, pairs\n",
        "\n",
        "# Retorna True si ambas sentencias en el par tienen una cantidad de palabras menores que MAX_LENGTH\n",
        "def filtrarPar(p):\n",
        "    # Las sentencias de entrada, necesitamos un espacio para el token SOS\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "# Filtra los pares usando la función filtrarPares\n",
        "def filtrarPares(pairs):\n",
        "    return [pair for pair in pairs if filtrarPar(pair)]\n",
        "\n",
        "# Usando las funciones definidas arriba generamos el diccionario que mapea de palabras a índices\n",
        "# devolverá el objeto voc y la lista de pares\n",
        "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
        "    print(\"Empieza la preparación de la data ...\")\n",
        "    voc, pairs = readVocs(datafile, corpus_name)\n",
        "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
        "    pairs = filtrarPares(pairs)\n",
        "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "    print(\"Contando las palabras...\")\n",
        "    for pair in pairs:\n",
        "        voc.agregarSentencia(pair[0])\n",
        "\n",
        "        \n",
        "        voc.agregarSentencia(pair[1])\n",
        "        \n",
        "\n",
        "    print(\"Cantidad total de palabras:\", voc.num_words)\n",
        "    \n",
        "    \n",
        "    return voc, pairs\n",
        "\n",
        "\n",
        "\n",
        "save_dir = \"./\"\n",
        "datafile = \"METALW.txt\"\n",
        "corpus = \"./\"\n",
        "corpus_name = \"dataf_s2s\"\n",
        "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
        "# Print some pairs to validate\n",
        "print(\"\\npairs:\")\n",
        "\n",
        "for pair in pairs[:10]:\n",
        "    print(pair)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empieza la preparación de la data ...\n",
            "Leyendo líneas...\n",
            "Read 319593 sentence pairs\n",
            "Trimmed to 175166 sentence pairs\n",
            "Contando las palabras...\n",
            "Cantidad total de palabras: 40305\n",
            "\n",
            "pairs:\n",
            "['hola ¿en qué puedo ayudarle?', 'sí']\n",
            "['sí', '¿cómo puedo ser de ayuda?']\n",
            "['¿cómo puedo ser de ayuda?', 'quiero saber sobre la política que tengo']\n",
            "['quiero saber sobre la política que tengo', 'bien ¿puedo conseguir tu nombre por favor?']\n",
            "['bien ¿puedo conseguir tu nombre por favor?', '¿cubre los daños causados por el agua?']\n",
            "['hola ¿en qué puedo ayudarle?', 'tengo una pregunta sobre mi política']\n",
            "['tengo una pregunta sobre mi política', 'seguro ¿puedes decirme tu número de póliza?']\n",
            "['seguro ¿puedes decirme tu número de póliza?', '3425512']\n",
            "['3425512', 'bien tengo tu póliza aquí ¿cuál es tu pregunta?']\n",
            "['bien tengo tu póliza aquí ¿cuál es tu pregunta?', 'cubre los daños causados por el agua?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5bAbcDjZRmN"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, entrada_voc, salida_voc, pares, max_length):\n",
        "        self.entrada_voc = entrada_voc\n",
        "        self.salida_voc = salida_voc\n",
        "        self.pares = pares\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.pares)\n",
        "        \n",
        "    def __getitem__(self, ix):        \n",
        "        entrada = torch.tensor(self.entrada_voc.indiceDeSentencia(self.pares[ix][0]), device=device, dtype=torch.long)\n",
        "        salida = torch.tensor(self.salida_voc.indiceDeSentencia(self.pares[ix][1]), device=device, dtype=torch.long)\n",
        "        # metemos padding a todas las frases hast a la longitud máxima\n",
        "        return torch.nn.functional.pad(entrada, (0, self.max_length - len(entrada)), 'constant', self.entrada_voc.word2index['PAD']), \\\n",
        "            torch.nn.functional.pad(salida, (0, self.max_length - len(salida)), 'constant', self.salida_voc.word2index['PAD'])\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW-Vqn-U6LZ-"
      },
      "source": [
        "## División de la data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd5pXKkX6THJ"
      },
      "source": [
        "df = pd.DataFrame(pairs, columns =['Pregunta', 'Respuesta'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Pregunta'], df['Respuesta'], test_size=0.20, random_state=42)\n",
        "\n",
        "train = pd.concat([X_train, y_train], axis=1).values.tolist()\n",
        "test = pd.concat([X_test, y_test], axis=1).values.tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KNzNyv6ass9",
        "outputId": "6e722869-d57d-402f-ce8d-63220d473516"
      },
      "source": [
        "dataset = {\n",
        "    'train': Dataset(voc, voc, train, max_length=MAX_LENGTH),\n",
        "    'test': Dataset(voc, voc, test, max_length=MAX_LENGTH)\n",
        "}\n",
        "\n",
        "len(dataset['train']), len(dataset['test'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140132, 35034)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KblpohTqbWq9",
        "outputId": "e8a23598-54df-43d7-b1db-90e3b39233f7"
      },
      "source": [
        "entrada, salida = dataset['test'][150]\n",
        "entrada.shape, salida.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRrtqQ7b32d7"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_gLJKgtcn3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296e5f29-9c21-493c-cedd-7e0bf1811dcd"
      },
      "source": [
        "voc.sentenciaDeIndice(entrada.tolist()), voc.sentenciaDeIndice(salida.tolist())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['hola',\n",
              "  '¿en',\n",
              "  'qué',\n",
              "  'puedo',\n",
              "  'ayudarle?',\n",
              "  'EOS',\n",
              "  'PAD',\n",
              "  'PAD',\n",
              "  'PAD',\n",
              "  'PAD'],\n",
              " ['necesito',\n",
              "  'saber',\n",
              "  'si',\n",
              "  'dejé',\n",
              "  'las',\n",
              "  'puertas',\n",
              "  'abiertas',\n",
              "  'EOS',\n",
              "  'PAD',\n",
              "  'PAD'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYj4rABNpdFZ"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwYBN97Lper4"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, longitud_entrada, longitud_embedding=100, longitud_oculta=100, n_capas=2):\n",
        "    super().__init__()\n",
        "    self.longitud_oculta = longitud_oculta\n",
        "    self.embedding = torch.nn.Embedding(longitud_entrada, longitud_embedding)\n",
        "    self.gru = torch.nn.GRU(longitud_embedding, longitud_oculta, num_layers=n_capas, batch_first=True)\n",
        "\n",
        "  def forward(self, oraciones_entrada):\n",
        "    embedded = self.embedding(oraciones_entrada)\n",
        "    salidas, oculta = self.gru(embedded)\n",
        "    return salidas, oculta"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db5TnKnKsCIn"
      },
      "source": [
        "class AtencionDecoder(torch.nn.Module):\n",
        "  def __init__(self, longitud_entrada, longitud_embedding=100, longitud_oculta=100, n_layers=2, longitud_maxima=MAX_LENGTH):\n",
        "    super().__init__()\n",
        "    self.embedding = torch.nn.Embedding(longitud_entrada, longitud_embedding)\n",
        "    self.gru = torch.nn.GRU(longitud_embedding, longitud_oculta, num_layers=n_layers, batch_first=True)\n",
        "    self.out = torch.nn.Linear(longitud_oculta, longitud_entrada)\n",
        "\n",
        "    self.atencion = torch.nn.Linear(longitud_oculta + longitud_embedding, longitud_maxima)\n",
        "    self.combinar_atencion = torch.nn.Linear(longitud_oculta * 2, longitud_oculta)\n",
        "\n",
        "  def forward(self, palabras_entrada, oculta, salidas_encoder):\n",
        "    embedded = self.embedding(palabras_entrada)\n",
        "    pesos_atencion = torch.nn.functional.softmax(self.atencion(torch.cat((embedded.squeeze(1), oculta[0]), 1)))\n",
        "    atencion_aplicada = torch.bmm(pesos_atencion.unsqueeze(1), salidas_encoder)\n",
        "    salida = torch.cat((embedded.squeeze(1), atencion_aplicada.squeeze(1)), 1)\n",
        "    salida = self.combinar_atencion(salida)\n",
        "    salida = torch.nn.functional.relu(salida)\n",
        "    salida, oculta = self.gru(salida.unsqueeze(1), oculta)\n",
        "    salida = self.out(salida.squeeze(1))\n",
        "    return salida, oculta, pesos_atencion"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sukDQKL8uuxv",
        "outputId": "64c139cb-a0ed-4332-b064-8dcf0c0c57f5"
      },
      "source": [
        "voc.num_words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40305"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5roEG491phYv"
      },
      "source": [
        "encoder = Encoder(longitud_entrada=voc.num_words)\n",
        "decoder = AtencionDecoder(longitud_entrada=voc.num_words)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us3MCcbeDYXO"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZdJL-x-dPs0",
        "outputId": "6f41b528-f318-473f-8926-6f7b0a870a5b"
      },
      "source": [
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=512, shuffle=True),\n",
        "    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=512, shuffle=False),\n",
        "}\n",
        "\n",
        "entrada, salida = next(iter(dataloader['test']))\n",
        "entrada.shape, salida.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([512, 10]), torch.Size([512, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XlLVGRC3uR7"
      },
      "source": [
        "def entrenamiento(encoder, decoder, epochs=10):\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "    encoder_optimizador = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
        "    decoder_optimizador = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        train_perdida = []\n",
        "\n",
        "        batches = tqdm(dataloader['train'])\n",
        "        \n",
        "        for batch in batches:\n",
        "            entrada_sentencia, salida_sentencia = batch\n",
        "            base = entrada_sentencia.shape[0]\n",
        "            perdida = 0\n",
        "            encoder_optimizador.zero_grad()\n",
        "            decoder_optimizador.zero_grad()\n",
        "            # obteniendo el último estado oculto del encoder\n",
        "            encoder_salida, oculta = encoder(entrada_sentencia)\n",
        "            # calculando las salidas del decoder de manera recurrente\n",
        "            decoder_entrada = torch.tensor([[voc.word2index['SOS']] for b in range(base)], device=device)\n",
        "            for i in range(salida_sentencia.shape[1]):\n",
        "                salida, oculta, peso_atencion = decoder(decoder_entrada, oculta, encoder_salida)\n",
        "                perdida += criterion(salida, salida_sentencia[:, i].view(base))\n",
        "                # el siguiente input será la palabra predicha\n",
        "                decoder_entrada = torch.argmax(salida, axis=1).view(base, 1)\n",
        "            # optimizacion\n",
        "            perdida.backward()\n",
        "            encoder_optimizador.step()\n",
        "            decoder_optimizador.step()\n",
        "            train_perdida.append(perdida.item())\n",
        "            batches.set_description(f'Epoch {epoch}/{epochs} loss {np.mean(train_perdida):.5f}')\n",
        "        \n",
        "        \n",
        "        val_loss = []\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "\n",
        "            batches = tqdm(dataloader['test'])\n",
        "\n",
        "            for batch in batches:\n",
        "                entrada_sentencia , salida_sentencia = batch\n",
        "                base = entrada_sentencia.shape[0]\n",
        "                perdida = 0\n",
        "                #obtenemos el último estado oculto del encoder\n",
        "                encoder_salida, oculta = encoder(entrada_sentencia)\n",
        "                # calculando las salidas del decoder de manera recurrente\n",
        "                decoder_entrada = torch.tensor([[voc.word2index['SOS']] for b in range(base)], device=device)\n",
        "                for i in range(salida_sentencia.shape[1]):\n",
        "                    salida, oculta, peso_atencion = decoder(decoder_entrada, oculta, encoder_salida)\n",
        "                    perdida += criterion(salida, salida_sentencia[:, i].view(base))\n",
        "                    # el siguiente input será la palabra predicha\n",
        "                    decoder_entrada = torch.argmax(salida, axis=1).view(base, 1)\n",
        "                val_loss.append(perdida.item())\n",
        "                batches.set_description(f'Epoch {epoch}/{epoch} val_loss {np.mean(val_loss):.5f}')\n",
        "            "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps8Ecl6XJUuB"
      },
      "source": [
        "entrenamiento(encoder, decoder, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSMYvk7Nhu2J",
        "outputId": "777d9f8a-00dd-4161-d3f6-d0c04a3309b0"
      },
      "source": [
        "entrenamiento(encoder, decoder, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/274 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n",
            "Epoch 1/30 loss 45.54411: 100%|██████████| 274/274 [00:41<00:00,  6.54it/s]\n",
            "Epoch 1/1 val_loss 40.16686: 100%|██████████| 69/69 [00:06<00:00, 11.15it/s]\n",
            "Epoch 2/30 loss 39.53362: 100%|██████████| 274/274 [00:42<00:00,  6.44it/s]\n",
            "Epoch 2/2 val_loss 39.09710: 100%|██████████| 69/69 [00:06<00:00, 11.10it/s]\n",
            "Epoch 3/30 loss 38.15269: 100%|██████████| 274/274 [00:42<00:00,  6.44it/s]\n",
            "Epoch 3/3 val_loss 38.22123: 100%|██████████| 69/69 [00:06<00:00, 10.94it/s]\n",
            "Epoch 4/30 loss 37.46347: 100%|██████████| 274/274 [00:42<00:00,  6.37it/s]\n",
            "Epoch 4/4 val_loss 37.93550: 100%|██████████| 69/69 [00:06<00:00, 11.12it/s]\n",
            "Epoch 5/30 loss 36.98956: 100%|██████████| 274/274 [00:43<00:00,  6.36it/s]\n",
            "Epoch 5/5 val_loss 37.76735: 100%|██████████| 69/69 [00:06<00:00, 10.78it/s]\n",
            "Epoch 6/30 loss 36.58492: 100%|██████████| 274/274 [00:42<00:00,  6.40it/s]\n",
            "Epoch 6/6 val_loss 37.62004: 100%|██████████| 69/69 [00:06<00:00, 10.72it/s]\n",
            "Epoch 7/30 loss 36.20360: 100%|██████████| 274/274 [00:43<00:00,  6.32it/s]\n",
            "Epoch 7/7 val_loss 37.55938: 100%|██████████| 69/69 [00:06<00:00, 10.49it/s]\n",
            "Epoch 8/30 loss 35.84314: 100%|██████████| 274/274 [00:44<00:00,  6.22it/s]\n",
            "Epoch 8/8 val_loss 37.49105: 100%|██████████| 69/69 [00:06<00:00, 11.08it/s]\n",
            "Epoch 9/30 loss 35.47703: 100%|██████████| 274/274 [00:43<00:00,  6.25it/s]\n",
            "Epoch 9/9 val_loss 37.58442: 100%|██████████| 69/69 [00:06<00:00, 10.77it/s]\n",
            "Epoch 10/30 loss 35.12539: 100%|██████████| 274/274 [00:43<00:00,  6.35it/s]\n",
            "Epoch 10/10 val_loss 37.56707: 100%|██████████| 69/69 [00:06<00:00, 10.33it/s]\n",
            "Epoch 11/30 loss 34.77779: 100%|██████████| 274/274 [00:43<00:00,  6.25it/s]\n",
            "Epoch 11/11 val_loss 37.64056: 100%|██████████| 69/69 [00:06<00:00, 10.88it/s]\n",
            "Epoch 12/30 loss 34.43528: 100%|██████████| 274/274 [00:43<00:00,  6.32it/s]\n",
            "Epoch 12/12 val_loss 37.75076: 100%|██████████| 69/69 [00:06<00:00, 10.46it/s]\n",
            "Epoch 13/30 loss 34.10565: 100%|██████████| 274/274 [00:43<00:00,  6.34it/s]\n",
            "Epoch 13/13 val_loss 38.04652: 100%|██████████| 69/69 [00:06<00:00, 10.94it/s]\n",
            "Epoch 14/30 loss 33.79371: 100%|██████████| 274/274 [00:43<00:00,  6.30it/s]\n",
            "Epoch 14/14 val_loss 38.13352: 100%|██████████| 69/69 [00:06<00:00, 11.03it/s]\n",
            "Epoch 15/30 loss 33.48378: 100%|██████████| 274/274 [00:43<00:00,  6.30it/s]\n",
            "Epoch 15/15 val_loss 38.38978: 100%|██████████| 69/69 [00:06<00:00, 10.97it/s]\n",
            "Epoch 16/30 loss 33.19093: 100%|██████████| 274/274 [00:43<00:00,  6.33it/s]\n",
            "Epoch 16/16 val_loss 38.45039: 100%|██████████| 69/69 [00:06<00:00, 10.65it/s]\n",
            "Epoch 17/30 loss 32.91070: 100%|██████████| 274/274 [00:43<00:00,  6.25it/s]\n",
            "Epoch 17/17 val_loss 38.80595: 100%|██████████| 69/69 [00:06<00:00, 11.00it/s]\n",
            "Epoch 18/30 loss 32.63535: 100%|██████████| 274/274 [00:43<00:00,  6.33it/s]\n",
            "Epoch 18/18 val_loss 38.80550: 100%|██████████| 69/69 [00:06<00:00, 10.57it/s]\n",
            "Epoch 19/30 loss 32.38619: 100%|██████████| 274/274 [00:43<00:00,  6.36it/s]\n",
            "Epoch 19/19 val_loss 39.16689: 100%|██████████| 69/69 [00:06<00:00, 11.10it/s]\n",
            "Epoch 20/30 loss 32.13791: 100%|██████████| 274/274 [00:43<00:00,  6.30it/s]\n",
            "Epoch 20/20 val_loss 39.39291: 100%|██████████| 69/69 [00:06<00:00, 10.84it/s]\n",
            "Epoch 21/30 loss 31.89495: 100%|██████████| 274/274 [00:43<00:00,  6.30it/s]\n",
            "Epoch 21/21 val_loss 39.72079: 100%|██████████| 69/69 [00:06<00:00, 11.10it/s]\n",
            "Epoch 22/30 loss 31.66110: 100%|██████████| 274/274 [00:43<00:00,  6.34it/s]\n",
            "Epoch 22/22 val_loss 39.81611: 100%|██████████| 69/69 [00:06<00:00, 10.67it/s]\n",
            "Epoch 23/30 loss 31.44703: 100%|██████████| 274/274 [00:42<00:00,  6.38it/s]\n",
            "Epoch 23/23 val_loss 40.28205: 100%|██████████| 69/69 [00:06<00:00, 10.80it/s]\n",
            "Epoch 24/30 loss 31.23668: 100%|██████████| 274/274 [00:43<00:00,  6.27it/s]\n",
            "Epoch 24/24 val_loss 40.55081: 100%|██████████| 69/69 [00:06<00:00, 10.66it/s]\n",
            "Epoch 25/30 loss 31.02759: 100%|██████████| 274/274 [00:43<00:00,  6.36it/s]\n",
            "Epoch 25/25 val_loss 40.64106: 100%|██████████| 69/69 [00:06<00:00, 11.10it/s]\n",
            "Epoch 26/30 loss 30.83533: 100%|██████████| 274/274 [00:43<00:00,  6.29it/s]\n",
            "Epoch 26/26 val_loss 40.69338: 100%|██████████| 69/69 [00:06<00:00, 11.10it/s]\n",
            "Epoch 27/30 loss 30.65405: 100%|██████████| 274/274 [00:43<00:00,  6.31it/s]\n",
            "Epoch 27/27 val_loss 41.12972: 100%|██████████| 69/69 [00:06<00:00, 11.15it/s]\n",
            "Epoch 28/30 loss 30.46518: 100%|██████████| 274/274 [00:43<00:00,  6.36it/s]\n",
            "Epoch 28/28 val_loss 41.16872: 100%|██████████| 69/69 [00:06<00:00, 10.61it/s]\n",
            "Epoch 29/30 loss 30.28811: 100%|██████████| 274/274 [00:43<00:00,  6.37it/s]\n",
            "Epoch 29/29 val_loss 41.61979: 100%|██████████| 69/69 [00:06<00:00, 11.10it/s]\n",
            "Epoch 30/30 loss 30.11851: 100%|██████████| 274/274 [00:43<00:00,  6.27it/s]\n",
            "Epoch 30/30 val_loss 41.44170: 100%|██████████| 69/69 [00:06<00:00, 10.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3SCXSEJ5vjN"
      },
      "source": [
        "# Guardar modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ8VbDi44lZj"
      },
      "source": [
        "torch.save({'encoder':encoder.state_dict(),\n",
        "            'decoder':decoder.state_dict()},\n",
        "            'checkpoint-10ML-60ep-META-512bz-loss26-valoss46-con-tildes2.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NygcFArHCmBr"
      },
      "source": [
        "# Cargar modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU0Zow6mCp3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced7c266-89f9-4015-ce76-9fe4d79081eb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/iA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/iA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-A0TaTu-3em",
        "outputId": "625f494a-74fc-4f99-d4b4-62112b49ae8b"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "20.txt\n",
            "BackwardForward.ipynb\n",
            "checkpoint-10ML-30ep-META-512bz-loss29-valoss41.pt\n",
            "checkpoint-10ML-30ep-META-512bz-loss30-valoss41-con-tildes.pt\n",
            "checkpoint-15ML-20EP.pt\n",
            "checkpoint-15ML-30ep-META-512bz-loss40-valoss54-con-tildes.pt\n",
            "checkpoint2.pt\n",
            "checkpoint-50ML-20EP.pt\n",
            "checkpoint.pt\n",
            "\u001b[0m\u001b[01;34mcontinnuacion\u001b[0m/\n",
            "cultura_general_1\n",
            "data_freider.txt\n",
            "\u001b[01;34mData_PC2\u001b[0m/\n",
            "final.txt\n",
            "GRL_Book.pdf\n",
            "METALW.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTOTz7-cM8MW",
        "outputId": "79c1ea13-b1f3-494a-83bb-9fb6601acfa8"
      },
      "source": [
        "encoder = Encoder(longitud_entrada=voc.num_words).cuda()\n",
        "decoder = AtencionDecoder(longitud_entrada=voc.num_words).cuda()\n",
        "# checkpoint = torch.load('checkpoint.pt')\n",
        "checkpoint = torch.load('checkpoint-10ML-30ep-META-512bz-loss30-valoss41-con-tildes.pt')\n",
        "encoder.load_state_dict(checkpoint['encoder'])\n",
        "decoder.load_state_dict(checkpoint['decoder'])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuPlJViauNoI"
      },
      "source": [
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "     return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U80Q0pmctYei"
      },
      "source": [
        "def inputVar(l, voc):\n",
        "     #print(l)\n",
        "     print(l)\n",
        "     indexes_batch = [voc.word2index[sentence] for sentence in l.strip().split(' ')] + [EOS_token]\n",
        "     print(indexes_batch)\n",
        "     #lengths = torch.tensor(indexes_batch, device=device, dtype=torch.long)\n",
        "     #print(lengths)\n",
        "     #padList = zeroPadding(indexes_batch)\n",
        "     padVar = torch.tensor(indexes_batch, device=device, dtype=torch.long)\n",
        "     return torch.nn.functional.pad(padVar,(0,MAX_LENGTH-len(padVar)),'constant',voc.word2index['PAD'])  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhxCqkg85zpl"
      },
      "source": [
        "def predict(input_sentence):\n",
        "    # obtenemos el último estado oculto del encoder\n",
        "    print(\"encoder\")\n",
        "    encoder_outputs, hidden = encoder(input_sentence.unsqueeze(0))\n",
        "    # calculamos las salidas del decoder de manera recurrente\n",
        "    print(\"decoder\")\n",
        "    decoder_input = torch.tensor([[voc.word2index['SOS']]], device=device)\n",
        "    # iteramos hasta que el decoder nos de el token <eos>\n",
        "    outputs = []\n",
        "    decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
        "    i = 0\n",
        "    while True and i<MAX_LENGTH:\n",
        "        output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "        decoder_attentions[i] = attn_weights.data\n",
        "        i += 1\n",
        "        decoder_input = torch.argmax(output, axis=1).view(1, 1)\n",
        "        outputs.append(decoder_input.cpu().item())\n",
        "        if decoder_input.item() == voc.word2index['EOS']:\n",
        "            break\n",
        "    return voc.sentenciaDeIndice(outputs), decoder_attentions"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvqyECT_r6fa"
      },
      "source": [
        "* ¿quieres helado? Sí\n",
        "* ¿cómo te llamas? mi nombre\n",
        "* ¿hola? hola puedo\n",
        "* hola hola\n",
        "* ¿Como estás? estoy\n",
        "* ¿cuántos años tienes? 8\n",
        "* ¿estás bien? si si"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6451CREW-F3"
      },
      "source": [
        "* ¿cómo estás? estoy bien\n",
        "* cuántos años tienes? 122 años\n",
        "* hola hola\n",
        "* ¿cómo te llamas? mi nombre\n",
        "* tienes hambre? sí"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7_G2G4x6AW3",
        "outputId": "caf09186-4b0b-48a5-badd-7fa0dc344623"
      },
      "source": [
        "salidaTextual, salidaCodificada = predict(inputVar(\"tienes hambre?\",voc))\n",
        "print(salidaTextual)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tienes hambre?\n",
            "[106, 21930, 2]\n",
            "encoder\n",
            "decoder\n",
            "['sí', 'EOS']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ua7hX5VAGPI",
        "outputId": "be80969a-58f3-4a5f-9893-38380cc1b503"
      },
      "source": [
        "print(salidaTextual)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['no', 'EOS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Hmh6m_NF3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}